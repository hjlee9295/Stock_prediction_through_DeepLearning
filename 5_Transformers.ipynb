{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADL_final_Transformers.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRMjA_J-kByk",
        "outputId": "ddc54fd1-9b8f-4f37-d84a-4059177d3501"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import datetime\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import *\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "brYq1H-Ckcl-",
        "outputId": "b504db17-350b-4291-c33f-f64458e34a76"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ADL final project/data/final_input.csv', index_col = [0])\r\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume_x</th>\n",
              "      <th>Volume_y</th>\n",
              "      <th>MA</th>\n",
              "      <th>Returns</th>\n",
              "      <th>BBand_upper</th>\n",
              "      <th>BBand_middle</th>\n",
              "      <th>BBand_lower</th>\n",
              "      <th>Average Directional Index</th>\n",
              "      <th>Directional Index</th>\n",
              "      <th>MACD</th>\n",
              "      <th>MACD_signal</th>\n",
              "      <th>MACD hist</th>\n",
              "      <th>stochastic k</th>\n",
              "      <th>stochastic d</th>\n",
              "      <th>movement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>297.3300</td>\n",
              "      <td>297.325</td>\n",
              "      <td>297.3300</td>\n",
              "      <td>297.3250</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.0400</td>\n",
              "      <td>297.035000</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>297.2400</td>\n",
              "      <td>297.165</td>\n",
              "      <td>297.2400</td>\n",
              "      <td>297.1600</td>\n",
              "      <td>0.1050</td>\n",
              "      <td>0.0412</td>\n",
              "      <td>297.132857</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>297.9000</td>\n",
              "      <td>297.660</td>\n",
              "      <td>297.9250</td>\n",
              "      <td>297.5145</td>\n",
              "      <td>3.0150</td>\n",
              "      <td>2.6786</td>\n",
              "      <td>297.265714</td>\n",
              "      <td>0.000447</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>297.6695</td>\n",
              "      <td>297.785</td>\n",
              "      <td>297.8155</td>\n",
              "      <td>297.5945</td>\n",
              "      <td>3.1800</td>\n",
              "      <td>2.8610</td>\n",
              "      <td>297.403214</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>297.7850</td>\n",
              "      <td>297.815</td>\n",
              "      <td>297.9255</td>\n",
              "      <td>297.6850</td>\n",
              "      <td>3.0375</td>\n",
              "      <td>2.3263</td>\n",
              "      <td>297.468214</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Open    Close      High  ...  stochastic k  stochastic d  movement\n",
              "0  297.3300  297.325  297.3300  ...           NaN           NaN         1\n",
              "1  297.2400  297.165  297.2400  ...           NaN           NaN         1\n",
              "2  297.9000  297.660  297.9250  ...           NaN           NaN         1\n",
              "3  297.6695  297.785  297.8155  ...           NaN           NaN         1\n",
              "4  297.7850  297.815  297.9255  ...           NaN           NaN         1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSjldAHekiDI",
        "outputId": "55230ba9-baa5-4f66-b8e8-d7133328b75f"
      },
      "source": [
        "train_size = int(len(df) * .7)\r\n",
        "df_train =  df.iloc[:train_size]\r\n",
        "df_val = df.iloc[train_size:]\r\n",
        "\r\n",
        "print(len(df_train), len(df_val))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65218 27951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfZClw3WkjBD"
      },
      "source": [
        "#Scaling\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "\r\n",
        "feature_columns = ['Open', 'High', 'Low', 'Volume_x', 'Volume_y', 'MA', 'Returns',\r\n",
        "       'BBand_upper', 'BBand_middle', 'BBand_lower', 'Directional Index',\r\n",
        "       'Average Directional Index', 'MACD', 'MACD_signal', 'MACD hist',\r\n",
        "        'stochastic k', 'stochastic d']\r\n",
        "\r\n",
        "\r\n",
        "for feature in feature_columns:\r\n",
        "  df_train[feature] = scaler.fit_transform(df_train[[feature]].values)\r\n",
        "  df_val[feature] = scaler.transform(df_val[[feature]])\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxNGed4Ikjpw",
        "outputId": "b413b353-8743-487c-c668-1a1e2d8994ce"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "Y_train = df_train['movement']\r\n",
        "Y_val = df_val['movement']\r\n",
        "\r\n",
        "print(len(Y_train[Y_train == 1]), len(Y_train[Y_train == 0]))\r\n",
        "print(len(Y_val[Y_val == 1]), len(Y_val[Y_val == 0]))\r\n",
        "\r\n",
        "Y_train = to_categorical(Y_train, 2)\r\n",
        "Y_val = to_categorical(Y_val, 2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34209 31009\n",
            "14165 13786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrt0htO2kkcI"
      },
      "source": [
        "def convert_raw_samples_to_model_samples(scd_log_rtns, movements, window_size):\r\n",
        "    X, y = [], []\r\n",
        "    len_log_rtns = len(scd_log_rtns)\r\n",
        "    for i in range(window_size, len_log_rtns):\r\n",
        "        X.append(scd_log_rtns[i-window_size:i])\r\n",
        "        y.append(movements[i])\r\n",
        "    X, y = np.asarray(X), np.asarray(y)\r\n",
        "    #X = np.reshape(X, (X.shape[0], X.shape[1], 1))\r\n",
        "    return X, y\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EifaqFOQkled"
      },
      "source": [
        "df_train = df_train.dropna()\r\n",
        "df_train.index = np.arange(0,len(df_train))\r\n",
        "df_val.index = np.arange(0,len(df_val))\r\n",
        "\r\n",
        "df_train = df_train[feature_columns]\r\n",
        "df_val  = df_val[feature_columns]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtHrEsD2kmAL"
      },
      "source": [
        "#Different Window for transformers due to the lack of memory\r\n",
        "window_size = 64\r\n",
        "X_train, y_train = convert_raw_samples_to_model_samples(df_train, Y_train, window_size)\r\n",
        "X_val, y_val = convert_raw_samples_to_model_samples(df_val, Y_val, window_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN5rcvbCkta0"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dACQT4Veks1G"
      },
      "source": [
        "class Time2Vector(Layer):\r\n",
        "  def __init__(self, seq_len, **kwargs):\r\n",
        "    super(Time2Vector, self).__init__()\r\n",
        "    self.seq_len = seq_len\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    '''Initialize weights and biases with shape (batch, seq_len)'''\r\n",
        "    self.weights_linear = self.add_weight(name='weight_linear',\r\n",
        "                                shape=(int(self.seq_len),),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "    \r\n",
        "    self.bias_linear = self.add_weight(name='bias_linear',\r\n",
        "                                shape=(int(self.seq_len),),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "    \r\n",
        "    self.weights_periodic = self.add_weight(name='weight_periodic',\r\n",
        "                                shape=(int(self.seq_len),),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "\r\n",
        "    self.bias_periodic = self.add_weight(name='bias_periodic',\r\n",
        "                                shape=(int(self.seq_len),),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    '''Calculate linear and periodic time features'''\r\n",
        "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \r\n",
        "    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\r\n",
        "    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\r\n",
        "    \r\n",
        "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\r\n",
        "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\r\n",
        "    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\r\n",
        "   \r\n",
        "  def get_config(self): # Needed for saving and loading model with custom layer\r\n",
        "    config = super().get_config().copy()\r\n",
        "    config.update({'seq_len': self.seq_len})\r\n",
        "    return config"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j07fA4m_kxBN"
      },
      "source": [
        "from keras import backend as K\r\n",
        "\r\n",
        "def recall_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    return recall\r\n",
        "\r\n",
        "def precision_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    return precision\r\n",
        "\r\n",
        "def f1_m(y_true, y_pred):\r\n",
        "    precision = precision_m(y_true, y_pred)\r\n",
        "    recall = recall_m(y_true, y_pred)\r\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0h77i9kxP1"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"Confusion matrix.ipynb\r\n",
        "\r\n",
        "Automatically generated by Colaboratory.\r\n",
        "\r\n",
        "Original file is located at\r\n",
        "    https://colab.research.google.com/drive/1dbeSXmnx5b6mUMXXYMlYVw-V20-fDdPc\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def plot_confusion_matrix(cm,\r\n",
        "                          target_names,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=None,\r\n",
        "                          normalize=True):\r\n",
        "    \"\"\"\r\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\r\n",
        "\r\n",
        "    Arguments\r\n",
        "    ---------\r\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\r\n",
        "\r\n",
        "    target_names: given classification classes such as [0, 1, 2]\r\n",
        "                  the class names, for example: ['high', 'medium', 'low']\r\n",
        "\r\n",
        "    title:        the text to display at the top of the matrix\r\n",
        "\r\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\r\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\r\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\r\n",
        "\r\n",
        "    normalize:    If False, plot the raw numbers\r\n",
        "                  If True, plot the proportions\r\n",
        "\r\n",
        "    Usage\r\n",
        "    -----\r\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\r\n",
        "                                                              # sklearn.metrics.confusion_matrix\r\n",
        "                          normalize    = True,                # show proportions\r\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\r\n",
        "                          title        = best_estimator_name) # title of graph\r\n",
        "\r\n",
        "    Citiation\r\n",
        "    ---------\r\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    import matplotlib.pyplot as plt\r\n",
        "    import numpy as np\r\n",
        "    import itertools\r\n",
        "\r\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\r\n",
        "    misclass = 1 - accuracy\r\n",
        "\r\n",
        "    if cmap is None:\r\n",
        "        cmap = plt.get_cmap('Blues')\r\n",
        "\r\n",
        "    plt.figure(figsize=(8, 6))\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "\r\n",
        "    if target_names is not None:\r\n",
        "        tick_marks = np.arange(len(target_names))\r\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\r\n",
        "        plt.yticks(tick_marks, target_names)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "\r\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        if normalize:\r\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\r\n",
        "                     horizontalalignment=\"center\",\r\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "        else:\r\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\r\n",
        "                     horizontalalignment=\"center\",\r\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\r\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5A59Pkkyqs"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ggWaexekx-V"
      },
      "source": [
        "class SingleAttention(Layer):\r\n",
        "  def __init__(self, d_k, d_v):\r\n",
        "    super(SingleAttention, self).__init__()\r\n",
        "    self.d_k = d_k\r\n",
        "    self.d_v = d_v\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    self.query = Dense(self.d_k, \r\n",
        "                       input_shape=input_shape, \r\n",
        "                       kernel_initializer='glorot_uniform', \r\n",
        "                       bias_initializer='glorot_uniform')\r\n",
        "    \r\n",
        "    self.key = Dense(self.d_k, \r\n",
        "                     input_shape=input_shape, \r\n",
        "                     kernel_initializer='glorot_uniform', \r\n",
        "                     bias_initializer='glorot_uniform')\r\n",
        "    \r\n",
        "    self.value = Dense(self.d_v, \r\n",
        "                       input_shape=input_shape, \r\n",
        "                       kernel_initializer='glorot_uniform', \r\n",
        "                       bias_initializer='glorot_uniform')\r\n",
        "\r\n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\r\n",
        "    q = self.query(inputs[0])\r\n",
        "    k = self.key(inputs[1])\r\n",
        "\r\n",
        "    attn_weights = tf.matmul(q, k, transpose_b=True)\r\n",
        "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\r\n",
        "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\r\n",
        "    \r\n",
        "    v = self.value(inputs[2])\r\n",
        "    attn_out = tf.matmul(attn_weights, v)\r\n",
        "    return attn_out    \r\n",
        "\r\n",
        "#############################################################################\r\n",
        "\r\n",
        "class MultiAttention(Layer):\r\n",
        "  def __init__(self, d_k, d_v, n_heads):\r\n",
        "    super(MultiAttention, self).__init__()\r\n",
        "    self.d_k = d_k\r\n",
        "    self.d_v = d_v\r\n",
        "    self.n_heads = n_heads\r\n",
        "    self.attn_heads = list()\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    for n in range(self.n_heads):\r\n",
        "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \r\n",
        "    \r\n",
        "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \r\n",
        "    self.linear = Dense(input_shape[0][-1], \r\n",
        "                        input_shape=input_shape, \r\n",
        "                        kernel_initializer='glorot_uniform', \r\n",
        "                        bias_initializer='glorot_uniform')\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\r\n",
        "    concat_attn = tf.concat(attn, axis=-1)\r\n",
        "    multi_linear = self.linear(concat_attn)\r\n",
        "    return multi_linear   \r\n",
        "\r\n",
        "#############################################################################\r\n",
        "\r\n",
        "class TransformerEncoder(Layer):\r\n",
        "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\r\n",
        "    super(TransformerEncoder, self).__init__()\r\n",
        "    self.d_k = d_k\r\n",
        "    self.d_v = d_v\r\n",
        "    self.n_heads = n_heads\r\n",
        "    self.ff_dim = ff_dim\r\n",
        "    self.attn_heads = list()\r\n",
        "    self.dropout_rate = dropout\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\r\n",
        "    self.attn_dropout = Dropout(self.dropout_rate)\r\n",
        "    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\r\n",
        "\r\n",
        "    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\r\n",
        "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \r\n",
        "    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \r\n",
        "    self.ff_dropout = Dropout(self.dropout_rate)\r\n",
        "    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \r\n",
        "  \r\n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\r\n",
        "    attn_layer = self.attn_multi(inputs)\r\n",
        "    attn_layer = self.attn_dropout(attn_layer)\r\n",
        "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\r\n",
        "\r\n",
        "    ff_layer = self.ff_conv1D_1(attn_layer)\r\n",
        "    ff_layer = self.ff_conv1D_2(ff_layer)\r\n",
        "    ff_layer = self.ff_dropout(ff_layer)\r\n",
        "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\r\n",
        "    return ff_layer \r\n",
        "\r\n",
        "  def get_config(self): # Needed for saving and loading model with custom layer\r\n",
        "    config = super().get_config().copy()\r\n",
        "    config.update({'d_k': self.d_k,\r\n",
        "                   'd_v': self.d_v,\r\n",
        "                   'n_heads': self.n_heads,\r\n",
        "                   'ff_dim': self.ff_dim,\r\n",
        "                   'attn_heads': self.attn_heads,\r\n",
        "                   'dropout_rate': self.dropout_rate})\r\n",
        "    return config"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAE9h4eBk1Yy"
      },
      "source": [
        "def create_transformers(X, embedding, classification):\r\n",
        "  \r\n",
        "  d_k = 256\r\n",
        "  d_v = 256\r\n",
        "  n_heads = 12\r\n",
        "  ff_dim = 256\r\n",
        "\r\n",
        "  input_seq = Input(shape = (X.shape[1], X.shape[2]))\r\n",
        "\r\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\r\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\r\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\r\n",
        "\r\n",
        "  if embedding:\r\n",
        "    time_embedding = Time2Vector(X.shape[1])\r\n",
        "    x = time_embedding(input_seq)\r\n",
        "    x = Concatenate(axis=-1)([input_seq, x])\r\n",
        "    x = attn_layer1((x,x,x))\r\n",
        "  else:\r\n",
        "    x = attn_layer1((input_seq, input_seq, input_seq))\r\n",
        "  \r\n",
        "  x = attn_layer2((x,x,x))\r\n",
        "  x = attn_layer3((x,x,x))\r\n",
        "  x = GlobalAveragePooling1D(data_format='channels_first')(x)\r\n",
        "  x = Dropout(0.1)(x)\r\n",
        "  x = Dense(64, activation='relu')(x)\r\n",
        "  x = Dropout(0.1)(x)\r\n",
        "\r\n",
        "  if classification:\r\n",
        "    out = Dense(2, activation=\"softmax\", name=\"output\")(x)\r\n",
        "    model = Model(inputs = input_seq, outputs = out)\r\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(1e-5), metrics = ['accuracy'])\r\n",
        "  else:\r\n",
        "    out = Dense(1)(x)\r\n",
        "    model = Model(inputs = input_seq, outputs = out)\r\n",
        "    model.compile(loss = 'mse', optimizer = 'Adam', metrics = ['mae', 'mape'])\r\n",
        "  \r\n",
        "  return model\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19k7-Fnjk2Is",
        "outputId": "49d45a4f-2f85-4d81-d4b8-9e8c3aa2609c"
      },
      "source": [
        "#With Time Embedding\r\n",
        "model = create_transformers(X_train, True, True)\r\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 17)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time2_vector (Time2Vector)      (None, 64, 2)        256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 19)       0           input_1[0][0]                    \n",
            "                                                                 time2_vector[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder (Transforme (None, 64, 19)       252786      concatenate[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_1 (Transfor (None, 64, 19)       252786      transformer_encoder[0][0]        \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_2 (Transfor (None, 64, 19)       252786      transformer_encoder_1[0][0]      \n",
            "                                                                 transformer_encoder_1[0][0]      \n",
            "                                                                 transformer_encoder_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 64)           0           transformer_encoder_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 64)           0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           4160        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 2)            130         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 762,904\n",
            "Trainable params: 762,904\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Het6Q5dHlJOe",
        "outputId": "e6b49fc8-3a84-42c6-dc91-2a0e705b6505"
      },
      "source": [
        "history = model.fit(X_train, y_train,epochs=5,  validation_data=(X_val, y_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2036/2036 [==============================] - 729s 347ms/step - loss: 0.6899 - accuracy: 0.6083 - val_loss: 0.6805 - val_accuracy: 0.5810\n",
            "Epoch 2/5\n",
            "2036/2036 [==============================] - 718s 353ms/step - loss: 0.6493 - accuracy: 0.6771 - val_loss: 0.6944 - val_accuracy: 0.5620\n",
            "Epoch 3/5\n",
            "2036/2036 [==============================] - 713s 350ms/step - loss: 0.5877 - accuracy: 0.7210 - val_loss: 0.8290 - val_accuracy: 0.5334\n",
            "Epoch 4/5\n",
            "2036/2036 [==============================] - 686s 337ms/step - loss: 0.4215 - accuracy: 0.8274 - val_loss: 0.9617 - val_accuracy: 0.5249\n",
            "Epoch 5/5\n",
            "2036/2036 [==============================] - 737s 362ms/step - loss: 0.3422 - accuracy: 0.8575 - val_loss: 1.0708 - val_accuracy: 0.5253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRgtYhY9lLtM",
        "outputId": "9902552e-af38-497c-dcee-2d876aca1406"
      },
      "source": [
        "y_pred = model.predict(X_val)\r\n",
        "y_pred = [y_pred[i].argmax() for i in range(len(y_pred))]\r\n",
        "print(set(y_pred))\r\n",
        "\r\n",
        "num =[0,0]\r\n",
        "for i in range(len(y_pred)):\r\n",
        "  num[y_pred[i]] += 1 \r\n",
        "\r\n",
        "print(num)\r\n",
        "\r\n",
        "y_true =  [y_val[i].argmax() for i in range(len(y_val))]\r\n",
        "num =[0,0]\r\n",
        "for i in range(len(y_true)):\r\n",
        "  num[y_true[i]] += 1 \r\n",
        "print(num)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1}\n",
            "[13640, 14247]\n",
            "[13753, 14134]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv_4yoRhlMjB",
        "outputId": "0b4dd0af-93df-459d-f849-4b7fa7b2ef21"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.51      0.52     13753\n",
            "           1       0.53      0.54      0.53     14134\n",
            "\n",
            "    accuracy                           0.53     27887\n",
            "   macro avg       0.53      0.53      0.53     27887\n",
            "weighted avg       0.53      0.53      0.53     27887\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "qFJAe9M0lOqm",
        "outputId": "b45bb17b-7e53-432b-c38d-543c47b99e1c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "cm = confusion_matrix(y_true, y_pred)\r\n",
        "plot_confusion_matrix(cm,\r\n",
        "                      ['upward','downward'],\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=None,\r\n",
        "                      normalize=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAHCCAYAAAAHPAuJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xdVbn/8c93ZjJppJIEQghFqvQSqoIUgdAEEekK6P0hCChNpHgBUexegQuCiCBcuPQiAhKQK1VpCaG3SAtJSCAJ6W1mnt8fe53kZDItmTlzJvt8377Oi3PWXnvvdSbjPPtZa+21FRGYmZlZPlWVuwFmZmZWOg70ZmZmOeZAb2ZmlmMO9GZmZjnmQG9mZpZjDvRmZmY55kBvVkaSekr6q6QZku5ox3GOlvRwR7atXCTtIumtcrfDLC/k++jNWifpKOAMYGNgFjAWuCQinmrncb8BnArsHBF17W5oFycpgA0iYly522JWKZzRm7VC0hnApcDPgNWAtYDfAwd1wOHXBt6uhCDfFpJqyt0Gs7xxoDdrgaR+wMXAyRFxd0TMiYhFEfHXiPhBqtNd0qWSJqbXpZK6p227SfpI0pmSpkiaJOn4tO3HwAXA4ZJmS/q2pIsk3VR0/nUkRSEASjpO0ruSZkl6T9LRReVPFe23s6Tn05DA85J2Ltr2mKSfSHo6HedhSYOa+f6F9p9d1P6DJe0n6W1J0ySdV1R/e0n/kvRZqnuFpNq07YlU7aX0fQ8vOv4PJX0MXF8oS/usl86xTfq8hqRPJO3Wrn9YswriQG/Wsp2AHsA9LdQ5H9gR2ArYEtge+FHR9tWBfsAw4NvAlZIGRMSFZL0Et0XEKhHxp5YaIqk3cDmwb0T0AXYmG0JoXG8g8ECquyrwX8ADklYtqnYUcDwwBKgFzmrh1KuT/QyGkV2Y/BE4BtgW2AX4T0nrprr1wOnAILKf3Z7AdwEiYtdUZ8v0fW8rOv5Ast6NE4pPHBH/Bn4I3CSpF3A9cENEPNZCe82siAO9WctWBT5tpWv9aODiiJgSEZ8APwa+UbR9Udq+KCIeBGYDG61gexqAzST1jIhJEfFaE3X2B96JiP+JiLqIuAV4EziwqM71EfF2RMwDbie7SGnOIrL5CIuAW8mC+GURMSud/3WyCxwiYnREPJPO+z7wB+BLbfhOF0bEgtSepUTEH4FxwLPAULILKzNrIwd6s5ZNBQa1Mna8BvBB0ecPUtniYzS6UJgLrLK8DYmIOcDhwInAJEkPSNq4De0ptGlY0eePl6M9UyOiPr0vBOLJRdvnFfaXtKGk+yV9LGkmWY9Fk8MCRT6JiPmt1PkjsBnw3xGxoJW6ZlbEgd6sZf8CFgAHt1BnIlm3c8FaqWxFzAF6FX1evXhjRIyKiL3IMts3yQJga+0ptGnCCrZpeVxF1q4NIqIvcB6gVvZp8dYfSauQTYb8E3BRGpowszZyoDdrQUTMIBuXvjJNQuslqZukfSX9KlW7BfiRpMFpUtsFwE3NHbMVY4FdJa2VJgKeW9ggaTVJB6Wx+gVkQwANTRzjQWBDSUdJqpF0OLAJcP8Ktml59AFmArNTb8NJjbZPBj63nMe8DHghIv6DbO7B1e1upVkFcaA3a0VE/JbsHvofAZ8A44FTgHtTlZ8CLwAvA68AY1LZipzrEeC2dKzRLB2cq1I7JgLTyMa+GwdSImIqcABwJtnQw9nAARHx6Yq0aTmdRTbRbxZZb8NtjbZfBNyQZuUf1trBJB0EjGTJ9zwD2KZwt4GZtc4L5piZmeWYM3ozM7Mcc6A3MzPLMQd6MzOzHHOgNzMzyzEHejMzsxzzk6LaqUffAdFn8BqtVzTrAob26VHuJpi12Ssvjfk0IgaX+jzVfdeOqFtm9eXlEvM+GRURIzuoSR3Kgb6d+gxeg6/98vZyN8OsTc7bfb1yN8GszdYe1LPxUs4lEXXz6L5Rq8s6tGj+2CtbW+q5bBzozcyswgmU35FsB3ozM6tsAtTaIxlWXg70ZmZmOc7o8/vNzMzMzBm9mZmZu+7NzMxyy5PxzMzM8i3HGX1+L2HMzMzMGb2ZmVU44a57MzOz/FKuu+4d6M3MzHKc0ef3m5mZmZkzejMzM3fdm5mZ5ZbvozczM8uvnD/UJr+XMGZmZuaM3szMzF33ZmZmueUxejMzs3yr8hi9mZmZrYSc0ZuZWWXzWvdmZmY5l+Pb6xzozcyswuV7Ml5+v5mZmZk5ozczM3PXvZmZWZ65697MzMxWRs7ozcyssknuujczM8u1HHfdO9CbmZnlOKPP7yWMmZmZOaM3M7NKl+8FcxzozczMctx170BvZmaVLecPtcnvNzMzMzNn9GZmVuk8Rm9mZpZvHqM3MzPLsRxn9Pn9ZmZmZuaM3szMzF33ZmZmeSVPxjMzM8u3HGf0+b2EMTMzM2f0ZmZmynFG70BvZmYVTTjQm5mZ5ZfSK6c8Rm9mZpZjzujNzKzCyV33ZmZmeeZAb2ZmlmN5DvQeozczM8sxZ/RmZlbx8pzRO9CbmVll8+11ZmZm+aU06749r1bPIW0kaWzRa6ak04q2nykpJA1KnyXpcknjJL0saZuiusdKeie9jm3t3M7ozczMSiwi3gK2ApBUDUwA7kmfhwN7Ax8W7bIvsEF67QBcBewgaSBwITACCGC0pPsiYnpz53ZGb2ZmFa/UGX0jewL/jogP0uffAWeTBe6Cg4AbI/MM0F/SUGAf4JGImJaC+yPAyJZO5ozezMwqXgdMxhsk6YWiz9dExDXN1D0CuCWd9yBgQkS81KgNw4DxRZ8/SmXNlTfLgd7MzCpeBwT6TyNiRBvOUwt8BThXUi/gPLJu+5Jx172ZmVnn2RcYExGTgfWAdYGXJL0PrAmMkbQ62Rj+8KL91kxlzZU3y4HezMwqmzrg1XZHkrrtI+KViBgSEetExDpk3fDbRMTHwH3AN9Ps+x2BGRExCRgF7C1pgKQBZL0Bo1o6obvuzcys4nXGgjmSegN7Ad9pQ/UHgf2AccBc4HiAiJgm6SfA86nexRExraUDOdCbmVlFUyc9vS4i5gCrtrB9naL3AZzcTL3rgOvael533ZuZmeWYM3ozM6t4XuvezMwsz/Ib5x3ozcyswinfGb3H6M3MzHLMGb2ZmVW8PGf0DvRmZlbxHOjNzMxyqrPuoy8Xj9GbmZnlmDN6MzOz/Cb0DvRmZlbhfHudmZmZrayc0ZuZWcXLc0bvQG9mZhXPgd5sOW2y2iocttXqVAmefu8zRr316VLbd1q7P4dssRqfzVsEwGPjpvH0+58BcOoX12Ldgb0YN3Uuv3/6w2WOfdiWq7Pzuv057d43Afj6lquz4eBeANRWV9Gnew1n3PdmKb+e5UyPblUM6J39OZwzv56Z8+ubrNeztorBfWr5+LMFLKwPAAb27kZtjRAwZ8GSfdfo352GyOoEMHnGQgD69ayhZ202alrfEEybvYh0KCun/MZ5B3rreAKO3Hoolz35PtPn1nHunp/j5YmzmDRrwVL1Ro+fwa1jP15m/4ffnkpt9TR2+dzAZbatNaAHvWqrlyq746Ulx9htvYEM79+jY76IVYwBvWuYMnMR9Q3B6v1qmbuogbpG0VdAnx41LFjUsLisV20VEnw8YyEChvbvzpyFDdQ3ZPtOmbmQhkZBfOb8OmbMy96v0qOavr1qmD6nroTfziqdJ+NZh1tnYE+mzF7Ip3MWUR/B8+NnsMUafdq8/1tT5rCgrmGZcgFf23x17n5lcrP7brdWP14YP2NFmm0VqrZG1NXH4uA8d0E9vbot+6exX68aZs6ro3HyXZUyQQmCIKLl9Lx4s/8Adx2S2vXqypzRW4cb0LMb01OXPMBn8xax7sCey9Tbelhf1h/UmymzF3DHSx8zfV7LWc3u6w/k5UmzmDm/6XoDe3VjUK9uvDllTvu+gFWU6iotDvIAdQ1B90aBvlu1qKkS8xc10LfoV3nuwgZ61lYzbEB3JJg+p64ogw+G9K0FYNb8euYsWDIc0K9nDb27V9MQwZSZC0v11ayNVoZg3R4O9M2Q9Gfg/oi4s9xtyaOXJ83i+fEzqGsIdll3AMduN4xLn/ig2fr9etSwzZp9+a/H32+2zojh/RgzYeYyGZdZew3o3Y2psxctU15bkwWHCdMXUCVYrV8t8xdlXfeTZy6kviHL+If0raWuvoEFddlv54x5dcyYV0ffHtX06VHDjFYucq308hzo3XMESPIFTweaPm8RA3p2W/y5f89uy2TrcxbWU5dSn6fem87aA5bN+IsN79+DwavU8pORG3DJvhtQW13FxSPXX6rOiDX78ry77W051TcE1VVL/sjXVIn6ovF5KcvoV+tbyxr9u9O9RgzqW0tttejdvZp5C7NMvSFgwaIGuqfgX59GnxoC5i1soLZm2T+3cxbWL56YZ1YqXe43TNI6kl4t+nyWpIskPSbpMkljJb0qafu0/RVJ/ZWZKumbqfxGSXul4z0paUx67Zy275bK7wNeT/tfIektSX8HhpTj++fBB9PnMWSVWlbt1Y1qie2G9+PlSbOWqtO3x5Jrqy3X6MOkmQsaH2Ypr348mx/e/zbn/+0dzv/bOyysb+CCh8Yt3r5an1p611bz7tR5HftlLPcW1gXdqrU42PfqXs28ogl3EVnGPvGz7LWgLvh05kIW1gd19UGP1M0voHtNFYvqA7FkErfIZvUvShcPNUUXFT1rq5eZ9Gfl4TH6rqNXRGwlaVfgOmAz4GngC8AHwLvALsCNwE7ASWR3tuwVEfMlbQDcAoxIx9sG2Cwi3pN0CLARsAmwGvB6Ooctp4aA28ZO4nu7rE2VxD/fn86kmQs4cJPBfDB9Pi9PmsUe6w9ki6F9aIgsq7nhhQmL9z9zt3VYvU93utdU8fP9NuR/Rk/g9cktj7tvN7yfs3lbYdPm1DGkb9YLNWdBPYvqg349a1hY17BU0G9s9vx6Vl2lG6v3q0XA7LRvdZUY3GdJr9bchfXMT8fp36uGmupC1h9Mm7PskICVQdeO1e2ysgX6WwAi4glJfSX1B54EdiUL9FcBJ0gaBkyPiDmS+gFXSNoKqAc2LDrecxHxXnq/K3BLRNQDEyX9X3ONkHQCcALAKoOGduw3zIlXP57Nqx+PW6rsr69/svj9va9O4d5XpzS5728fe7/V4xfuoS+4v+jYZstr/qIGJn229KS45sbNiyfPBfBpE2P39Q3BxzOanmTXVH0rv66elbdHl+u6B+pYul3FN0U37uMK4AmyLH4X4DHgE+BQsgsAgNOBycCWZJl8bdH+KzQ9OyKuiYgRETGiR98BK3IIMzOzTtEVA/1kYIikVSV1Bw4o2nY4gKQvAjMiYkZEjAcGARtExLvAU8BZZBcAAP2ASRHRAHwDWHq1lSWeAA6XVC1pKLB7R38xMzPrguQx+k4VEYskXQw8B0wAivto50t6EegGfKuo/FmWBPAngZ+TBXyA3wN3pUl6D9F8Fn8PsAfZ2PyHwL/a/23MzKyrE9ndFXnV5QI9QERcDlxeXCbpMeCmiDitifrfKHr/T4p6KiLiHWCLouo/TOWPkXX1F+oFcEpHtN/MzFYmXT8rb4+u2HVvZmZmHaRLZvRNiYjdyt0GMzPLpxwn9CtPoDczMyuVPHfdO9CbmVllU74zeo/Rm5mZ5ZgzejMzq2gCqqrym9I70JuZWcXLc9e9A72ZmVW8PE/G8xi9mZlZjjmjNzOzypbzWfcO9GZmVtGyte7zG+kd6M3MrMJ5rXszMzNbSTmjNzOzipfjhN6B3szMLM9d9w70ZmZW2XI+695j9GZmZjnmjN7MzCqab68zMzPLuRzHeQd6MzOzPGf0HqM3MzPLMWf0ZmZW8XKc0DvQm5lZhVO+u+4d6M3MrKJls+7L3YrS8Ri9mZlZjjmjNzOzCpfvp9c50JuZWcXLcZx3172ZmVmeOaM3M7OK5657MzOzvMr50+sc6M3MrKLl/aE2HqM3MzPLMQd6MzOreJLa9WrD8TeSNLboNVPSaZJ+LelNSS9LukdS/6J9zpU0TtJbkvYpKh+ZysZJOqe1czvQm5lZxZPa92pNRLwVEVtFxFbAtsBc4B7gEWCziNgCeBs4N2uPNgGOADYFRgK/l1QtqRq4EtgX2AQ4MtVtlsfozcys4nXyGP2ewL8j4gPgg6LyZ4BD0/uDgFsjYgHwnqRxwPZp27iIeBdA0q2p7uvNncwZvZmZWfsNkvRC0euEFuoeAdzSRPm3gL+l98OA8UXbPkplzZU3yxm9mZlVto65ve7TiBjR6qmkWuArpC76ovLzgTrg5na3pBEHejMzq2jq3LXu9wXGRMTkxeeXjgMOAPaMiEjFE4DhRfutmcpoobxJ7ro3M7OKV+rJeEWOpKjbXtJI4GzgKxExt6jefcARkrpLWhfYAHgOeB7YQNK6qXfgiFS3Wc7ozczMOoGk3sBewHeKiq8AugOPpF6FZyLixIh4TdLtZJPs6oCTI6I+HecUYBRQDVwXEa+1dF4HejMzq3hVndB1HxFzgFUbla3fQv1LgEuaKH8QeLCt53WgNzOzipfjFXAd6M3MrLJl4+z5jfSejGdmZpZjzujNzKziVeU3oXegNzMzy3PXvQO9mZlVvBzHeY/Rm5mZ5ZkzejMzq2giWwY3rxzozcys4nkynpmZWV6pUx9q0+k8Rm9mZpZjzujNzKzi5Tihd6A3M7PKJjrnoTbl4kBvZmYVL8dx3mP0ZmZmeeaM3szMKl6eZ9070JuZWUXLHlNb7laUTrOBXtJ/A9Hc9oj4XklaZGZm1skqdTLeC53WCjMzMyuJZgN9RNxQ/FlSr4iYW/ommZmZda785vNtmHUvaSdJrwNvps9bSvp9yVtmZmbWSZSWwV3RV1fWltvrLgX2AaYCRMRLwK6lbJSZmVlnyRbMad+rK2vTffQRMb5RUX0J2mJmZmYdrC23142XtDMQkroB3wfeKG2zzMzMOslK0P3eHm0J9CcClwHDgInAKODkUjbKzMysM+U4zrce6CPiU+DoTmiLmZlZWeQ5o2/LrPvPSfqrpE8kTZH0F0mf64zGmZmZWfu0ZTLe/wK3A0OBNYA7gFtK2SgzM7PO4ln30Csi/ici6tLrJqBHqRtmZmbWWfJ8H31La90PTG//Jukc4Fayte8PBx7shLaZmZlZO7U0GW80WWAvXKp8p2hbAOeWqlFmZmadqWvn5O3T0lr363ZmQ8zMzMpBqtyn1y0maTNgE4rG5iPixlI1yszMrDPlOM63HuglXQjsRhboHwT2BZ4CHOjNzMy6uLbMuj8U2BP4OCKOB7YE+pW0VWZmZp2oImfdF5kXEQ2S6iT1BaYAw0vcLjMzs07TxWN1u7Ql0L8gqT/wR7KZ+LOBf5W0VWZmZp1EqLIn40XEd9PbqyU9BPSNiJdL2ywzMzPrCC0tmLNNS9siYkxpmmRmZtaJVLld979tYVsAe3RwW8zMzMqiq0+oa4+WFszZvTMbsrJaq39PLj1403I3w6xNBmx3SrmbYNYlteUWtJVVnr+bmZlZxWvTynhmZmZ5JSq0697MzKxSdPVnyrdHq133yhwj6YL0eS1J25e+aWZmZp2jSu17dWVtGaP/PbATcGT6PAu4smQtMjMzsw7Tlq77HSJiG0kvAkTEdEm1JW6XmZlZp5A8Rr9IUjXZvfNIGgw0lLRVZmZmnaird7+3R1sC/eXAPcAQSZeQPc3uRyVtlZmZWSfKcULfprXub5Y0muxRtQIOjog3St4yMzMza7dWA72ktYC5wF+LyyLiw1I2zMzMrDMIKvvpdcADZOPzAnoA6wJvAV731czMciHPy8S2pet+8+LP6al2322mupmZ2Uonxwn98l/EpMfT7lCCtpiZmVkHa8sY/RlFH6uAbYCJJWuRmZlZJ5JU8WP0fYre15GN2d9VmuaYmZl1vhzH+ZYDfVoop09EnNVJ7TEzM+t0eV4wp9kxekk1EVEPfKET22NmZmYdqKWM/jmy8fixku4D7gDmFDZGxN0lbpuZmVnJ5f0++rbMuu8BTAX2AA4ADkz/NTMzy4XswTYr/mr9+NpI0tii10xJp0kaKOkRSe+k/w5I9SXpcknjJL2cbm0vHOvYVP8dSce2du6WMvohacb9qyxZMKcgWv9aZmZmK4FOeKZ8RLwFbAWL579NIHuOzDnAoxHxC0nnpM8/BPYFNkivHYCrgB0kDQQuBEaQxeLRku6LiOnNnbuljL4aWCW9+hS9L7zMzMxs+e0J/DsiPgAOAm5I5TcAB6f3BwE3RuYZoL+kocA+wCMRMS0F90eAkS2drKWMflJEXNyOL2JmZrZSEJ06Rn8EcEt6v1pETErvPwZWS++HAeOL9vkolTVX3qyWAn1+ZyaYmZkl2WS8dh9mkKQXij5fExHXLHMuqRb4CnBu420REZI6fGi8pUC/Z0efzMzMrCvqgED/aUSMaEO9fYExETE5fZ4saWhETEpd81NS+QRgeNF+a6ayCcBujcofa+mEzY7RR8S0NjTYzMzM2u5IlnTbA9wHFGbOHwv8paj8m2n2/Y7AjNTFPwrYW9KANEN/71TWrLYsgWtmZpZr6oT76CX1BvYCvlNU/AvgdknfBj4ADkvlDwL7AeOAucDxkCXhkn4CPJ/qXdxaYu5Ab2ZmFa2DxuhbFRFzgFUblU2liaHyiAjg5GaOcx1wXVvP60BvZmaVrY2L3qyslvt59GZmZrbycEZvZmYVL89r3TvQm5lZReusMfpycaA3M7OKl+OE3mP0ZmZmeeaM3szMKpyoyvGq7w70ZmZW0YS77s3MzGwl5YzezMwqmzzr3szMLNd8H72ZmVlOeYzezMzMVlrO6M3MrOK5697MzCzHchznHejNzKyyiXyPY+f5u5mZmVU8Z/RmZlbZBMpx370DvZmZVbz8hnkHejMzq3DZ8+jzG+o9Rm9mZpZjzujNzKzi5Tefd6A3MzPzffRmZmb5pVzPuvcYvZmZWY45ozczs4qW95XxHOjNzKzi5bnr3oHezMwqXn7DfL57K8zMzCqeM3ozM6tsXuvezMwsvzwZz8zMLOfynNHn+SLGzMys4jmjNzOzipfffN6B3szMzGvdm5mZ5VU2GS+/kd5j9GZmZjnmjN7MzCqeu+7NzMxySyjHXfcO9GZmVvHynNF7jN7MzCzHnNGbmVlFy/usewd6MzOrbMp3170DvZmZVbw8B3qP0ZuZmeWYM3ozM6t4vr3OzMwspwRU5TfOO9CbmZnlOaP3GL2ZmVmOOaM3M7OKl+dZ9w70VhJVgprUX1TfAPXRfL3aalhQB4UqArpVL6mzsH7pfbpVZf+nLJTXVC0ZX4uARQ0d9S2sUuy18+f5zQ8Opbqqij/f+09+c/0jS20/5sAd+NnpBzNxygwArr7tcf58z79Ya+gAbv3tCVRViW411Vx16+Nce+dTAIz64/dZfVBf5i1YBMCBJ13BJ9Nn86szD2HX7TYEoFePWgYPXIWhu57did/WmpLnrnsHeiuJmipYVJ8F79pqaKhfEsgb12totKFb9ZJ9G2tqwkxdUWCvThcYdQ721kZVVeLScw5j/5OuYMLkz3jq5h9w/+Ov8Oa7Hy9V765RYzj9l3csVTbpk5nsduxvWbiojt49axl95/k88PgrTPokuyA4/vwbGPP6h0vtc/Zv7178/qQjvsSWG61Zom9mlvEYvXU4kWXWhUBd39B0gG4qIFdp6X3bso9Ze2y32Tr8e/ynvD9hKovq6rlj1BgO2G2LNu27qK6ehYvqAOhe242q5ez/PWzkttz+0OjlbrN1rMKs+/a8ujJn9NbhpKUDdZD+j1BUqPRqnM0X/v9S6J4v7vZvKcjXVGXZfLBsV79ZS9YY0o+PJk9f/HnC5Olsv9k6y9Q7aM+t+MI26zPuwymc/Zu7+GjyZwCsuVp/7r78JNYbPpjzLr13cTYP8IeLjqG+oYF7Hx3LL/740FLHW2voANZeY1Uee/6t0nwxWw75fkxtp2X0ki6SdFZnna+9JB0n6YpytyOvulU3H7SlbJx9YT1Up/H35i4MCuoaYEF9dmFQ434q62APPvEqG+9/Idsf/nMefeZN/njxNxZv+2jyZ2x/+M/Z7KAfc8yB2zNkYB8Ajj/vz2x32M/48rd+xxe2Xo+jDth+qWN+fZ9tuffRsTQ090ttnSetdd+eV1fmP4mJpOrWa1lbRLDUtXGhK59GZbXV0L16yftC0l9ct75h6W617tVL6tY28S9WH12/G826lolTZrDmagMWfx622gAmFGXlANNmzFncRX/9Pf9k68+vtcxxJn0yg9fGTeIL26yXHTcdY/bcBdz2txfYbtO1l6p/6D7bcvtDL3TodzFrSkkDvaTzJb0t6Slgo1S2laRnJL0s6R5JAyQNkTQ6bd9SUkhaK33+t6Rekv4s6XJJ/5T0rqRD0/YrJX0lvb9H0nXp/bckXZLe3ytptKTXJJ1Q1L7Zkn4r6SVgJ0nHp/Y+B3yhlD+bPAvSVW76XN3EhLsF9Utehe72IKtXfHVclbrj62NJ/YX1S3fRF8f1ai17UWHWkhde+4D11xrM2musSreaar6+zzY88NjLS9VZfVDfxe8P+NLmvPVeNlFv2JD+9OjeDYD+fXqy89br8fb7U6iurmLV/r0BqKmpYr9dN+O1f09afIwN11mNAX178cxL75X661kbqZ2vrqxkY/SStgWOALZK5xkDjAZuBE6NiMclXQxcGBGnSeohqS+wC/ACsEu6QJgSEXOV/fUfCnwR2Bi4D7gTeDLtcx8wLNUhld2a3n8rIqZJ6gk8L+muiJgK9AaejYgzJQ0F/hfYFpgB/AN4sVQ/n7yra1hyi1x9QxaYCzPsW+uprGtYkq23pX5N1ZKLA99eZ8urvr6B0395O3/9/clUV4kb/vIMb7z7Mf950v6Mef1DHnj8Fb575G7s/6XNqauvZ/qMufy/C28CYKN1V+cXZ3yVIBDi0hsf5bVxE+nVo5b7rjyZbjXVVFdX8Y9n3+S6u59efM6v77Mtd4zyJLyuIus17OrhesUpSpT+SDoNGBgRF6TP/0UWQL8dEYVsfT3gjojYRtIfgbuB44FbgJFkQXyLiDhb0p+BRyLi5rTvrIjoI2kYcBfwLeBsYABwIlmg3i4iZkm6CPhqato6wD4R8YykOqB7RGppxaoAABlrSURBVNRLOhg4JCK+mY7/PWDDiDilie92AnACwPC11tr27X9/0HE/OLMSGrDdMr/OZl3W/LFXjo6IEaU+z+c33zquv+cf7TrGThsM6JS2roiuNEb/BFkWvjbwF2BLsuz9yaI6C4reCyAiJgD9yS4Mnkj1DwNmpyC/G/BlYKeI2JIsS++RjjE/IpZ7jnZEXBMRIyJixOBBg5d3dzMzq0CS+ku6U9Kbkt6QtFPRcPZYSS9I2j7VVRquHpeGurcpOs6xkt5Jr2NbO28pA/0TwMGSekrqAxwIzAGmS9ol1fkG8Hh6/yRwDPBORDQA04D9gKfacK5ngNNYEujPYskFQj9geur+3xjYsZljPAt8SdKqkroBX2/7VzUzs5Va5wzSXwY8FBEbkyWzbwC/An4cEVsBF6TPAPsCG6TXCcBVAJIGAhcCOwDbAxdKGkALSjZGHxFjJN0GvARMAZ5Pm44FrpbUC3iXrKueiHhf2UD8E6neU8CaETGd1j0J7B0R4yR9AAxkSaB/CDhR0hvAW2QXBU21d1Lq4v8X8Bkwdnm+r5mZrbxKfR+9pH7ArsBxABGxEFgoKYDCbM9+wMT0/iDgxsjG159JvQFDgd3IhrGnpeM+QtajfUtz5y7pgjkRcQlwSRObmsyqI2J40fufAT8r+nxco7qrFL3/E/Cn9H4R2SS7wrYFZFdGTZ1vlUafrweub+77mJlZPnXCXLx1gU+A6yVtSTY5/ftkvdGjJP2GrJd951R/GDC+aP+PUllz5c3qSmP0ZmZmK6tBaYy98Dqh0fYaYBvgqojYmmwo+xzgJOD0lOieTkpaO5KXwDUzs4rXAQn9p63Muv8I+Cgink2f7yQL9F8ky+wB7gCuTe8nAMOL9l8zlU0g674vLn+spYY5ozczMyvxZLyI+BgYL2mjVLQn8DrZmPyXUtkewDvp/X3AN9Ps+x2BGRExCRgF7J0WmxsA7J3KmuWM3szMKloWqztlwZxTgZsl1bJkMvpfgMsk1QDzSWu0AA+S3Xk2DpjLkonr0yT9hCUT3C8uTMxrjgO9mZlZJ4iIsUDj7v2nyFZkbVw3gJObOc51wHVtPa8DvZmZVbaV4Al07eFAb2ZmFS/Hcd6B3szMLM+R3rPuzczMcswZvZmZVTh11qz7snCgNzOziufJeGZmZjm1fA+gW/l4jN7MzCzHnNGbmZnlOKV3oDczs4rnyXhmZmY5lufJeB6jNzMzyzFn9GZmVvFynNA70JuZWYXL+f11DvRmZlbx8jwZz2P0ZmZmOeaM3szMKprI96x7B3ozM6t4OY7zDvRmZmZ5jvQeozczM8sxZ/RmZlbx8jzr3oHezMwqnifjmZmZ5ViO47zH6M3MzPLMGb2ZmVmOU3oHejMzq2jZUvf5jfTuujczM8sxZ/RmZlbZ5Fn3ZmZmuZbjOO9Ab2ZmludI7zF6MzOzHHNGb2ZmFU65nnXvQG9mZhXPk/HMzMxySuR6iN5j9GZmZnnmjN7MzCzHKb0DvZmZVTxPxjMzM8uxPE/G8xi9mZlZjjmjNzOzipfjhN6B3szMKpwfamNmZpZ3+Y30HqM3MzPLMWf0ZmZW0YS77s3MzHItx3Hegd7MzCzPGb3H6M3MzHLMGb2ZmVU8L4FrZmaWZ/mN8w70ZmZmOY7zHqM3MzPLM2f0ZmZW0eQlcM3MzPLNk/HMzMzyLL9x3mP0ZmZmeeaM3szMKl6OE3oHejMzM0/GMzMzyy3lejKex+jNzMxyzIHezMwqWuF59O15tek8Un9Jd0p6U9IbknZK5aemstck/aqo/rmSxkl6S9I+ReUjU9k4See0dl533ZuZmXWOy4CHIuJQSbVAL0m7AwcBW0bEAklDACRtAhwBbAqsAfxd0obpOFcCewEfAc9Lui8iXm/upA70ZmZW8Uo9GU9SP2BX4DiAiFgILJR0EvCLiFiQyqekXQ4Cbk3l70kaB2yfto2LiHfTcW9NdZsN9O66NzMzK711gU+A6yW9KOlaSb2BDYFdJD0r6XFJ26X6w4DxRft/lMqaK2+WA72ZmVU8tfN/wCBJLxS9Tmh0ihpgG+CqiNgamAOck8oHAjsCPwBulzq2f8Fd92ZmVtk65qE2n0bEiBa2fwR8FBHPps93kgX6j4C7IyKA5yQ1AIOACcDwov3XTGW0UN4kZ/RmZlbR1AGv1kTEx8B4SRuloj3JxtXvBXYHSJPtaoFPgfuAIyR1l7QusAHwHPA8sIGkddOEviNS3WY5ozczM+scpwI3pwD9LnA8WRf+dZJeBRYCx6bs/jVJt5NdDNQBJ0dEPYCkU4BRQDVwXUS81tJJHejNzMw6YWG8iBgLNNW9f0wz9S8BLmmi/EHgwbae14HezMwqXp6XwHWgNzOzipfnh9p4Mp6ZmVmOOaM3M7OKl+OE3oHezMwsz5HeXfdmZmY55ozezMwqnmfdm5mZ5VThefR5pWwBHltRkj4BPih3O3JoENkykGYrA/++lsbaETG41CeR9BDZv2F7fBoRIzuiPR3Ngd66JEkvtPKACLMuw7+v1pV5Mp6ZmVmOOdCbmZnlmAO9dVXXlLsBZsvBv6/WZXmM3szMLMec0ZuZmeWYA72ZmVmOOdDbSklSdbnbYLaiJG0saeNyt8MqgwO9rXQkrQ4cJWmNcrfFbHlJ6gscCZwpacNyt8fyz4HeVkabA18H9pE0tNyNMWsrSYqImcDNwMfAqZLWKWujLPe81r2tdCLikZQJ7Q+sIunmiJhW7naZtSaW3Oa0O7BxeoWkKyPirfK1zPLMGb2tdCTtBxwOzAG+DxyauvPNuiRpySNTJO0BnAZ8F7iIbI38k53ZW6k40NtKRVIv4AfAjyLiWOBMYE/ga5JWLWvjzJpRyOQlDQOGAGMi4pOIuAt4FNgCuEDSemVspuWUA72tNCTtBgTwLrARQET8BfgHcDFwiKTuZWugWQskfRP4KfAcsKakwwAi4mmy3+nPgNnla6HllcfobaUgaQfgauA44FlguKQdIuJZ4ElgLPCviFhQvlaaNU3St4ERwK8j4l1J1wL7S9oSeIssoz84IiaXs52WT14C17o8SWsBtwH3RMSvJK0NnAqsTnaxuiXw/Yh4uIzNNGuWpCuBk4CtI+IlSUOA4cD3gLnAVRHxcjnbaPnlQG9dXhrXvBD4EnBgRLwtaSAwDNgMeDdl9mZll26hK4zJrxIRs9P7K8nuFNki3WJXqF8dEfXlaa1VAgd663IKfyjTxKRFwASysfmLyW5HOjci3ilnG82a0ijIfx/YhOx39/yImCrpcmAvYMeImFHGploF8WQ863JSkN8PuA84g2xWcjVZoH8FuMyzk60rKgryJwNfBc4ly+Kvk7RpRHwPeAb4v+Jb7sxKyYHeuhxJI4BfAQeSzVDeCXgpbf4lMAboV57WmbVMUg2wPnAM8A2yi9OJwLWSNo+I44H9wt2p1kncdW9diqRVgEFAb2Ao8DNgZ+BBYC2y5W/rI6KhbI00a0a6BbQ+Ip6UtCnw3xGxR9o2AbgVOM93h1hnckZvXYakDYCzIuL9iHgN+DJwU0TUkc26rwZGOMhbV9FoxTsBW5FdmEJ2T3yNpF0kfQV4CrjMQd46m++jt7IqmngnYDrZvcWTI+Iqsod+rC/pFOAw4KCIeL2c7TUrVjQmvwfZUra3AbdJej4i/k/S3cD5wJrAYRHxYflaa5XKXfdWdpL2BA4GLgUWAtcB55H94TwM2Bq4LSLuKVsjzZqR1nV4gKyH9CiyxW9OBg6JiAmSBgM1ETGpjM20CuZAb2XR6Dako4ArgDeAu4FpwJCI+GXK9BURDcX7mHUFkoZExBRJXwMuIFvl7m9kCzrdBFzprnorNwd6KxtJO5LdI/8RcAQgYG9gMPBF4IsR8Ur5Wmi2tEYXqFuRrWz3JnAX2RoPw8kuWC8B+gI7RMS8MjXXDPAYvZXXSGA74H6yMcz3yJYJ3RT4CbAa2a1JZmXXKMh3i4ixkv6bbNLoncDfgakR8TjwRUlrOshbV+BAb52maOLdpsAC4BfAumRL224DnAisEREXA/sW71OuNpvBMkH+DGAHSXXA8RHxoqSPgP8H7Jbq/pyst8qs7Hx7nXWaFOT3AR4GLgJeB3pFxNXAj8ge1bmvpOHF+5SjrWbFioL83sAhZBepDcCLknpExC1kE/BOAu4o3ses3DxGb51G0ibA98nujX9S0gnAD8huO3oxPaWuV0S8WdaGmiWNMvk9gO8CT0fE71LZDWR3hWwfEfMlVXmdB+tqnNFbp5C0IdnM+i2B3umJXdcANwBnSaqJiA8d5K0rKQryG5NNslsAbCHp82n7scA7wGOFXcrQTLMWOdBbyUkaSjarfizZojjbkD1iFrLJdvPS6ndmXYKkqvTfakn9yB6stBNwWqpycFGw/xpZd767661LcqC3kmj0ZK4pwHiyBXBeIbuF7peSLgb+k2zWvVmXUdT9vnZ6nGwhmPckG59fDzgy9VQBeDEc67Ic6K0k0sS7nSUdHRH1wI3A+8BMsm7OfsDngNMi4t6yNdSsSOECVZkdgXGSzgPWAP4J7BwRbwHXAAOBqeBM3ro2B3orpQHATyQdkYL9HUAvYAfgZbIFRQ6SNKiMbTRbrChgV0XEM2Sr2/UEdgG+BRyV7o9/DjgzIqaWqalmbeZAbyUTEQ+Q3XJ0rqSjImIR2a11s4HfAseRrSSmZg9i1skkfRH4h6QBwD/ILk7PIuuJ2gP4XRrDX1i2RpotB99eZyUnaSRZ1/3tZAvhfCci/p621XginpVTU4sySfox2ZK2d5HdAvoH4E9kqzm+GhHjO72hZivIgd46haTNyJ7T/XpEPFUYC/XYpnUVko4mm2T3CdmF6WZkSzQfQjZGf2BEvFO+FpqtGAd6M6tIktYApkfEPEmnAkcDt5Ity7wD8PWIGJ8eo/xL4CsRMbF8LTZbMQ70ZlZxJA0DzgFeJcvefwrcHhHPpu3nknXdfzci5kiqjQiPydtKyZPxzKwSTQRGAxuQZfKbkj1cqeABssl2c9PnRZ3aOrMO5KfXmVlFKXqKYhWwSXqNAU6VNC0irgU2Jxuv7wvM8FwSW5m5697MKk6aeHcWcDzwbbJVG/uTrYB3P7ArcHhEvFa2Rpp1EAd6M6s4afnlWRHxa0m1ZE+l24msO/92YHZEfFrONpp1FI/Rm1klGgN8QdKmEbEwIi4lW5J5VWCag7zlicfozawSPUZ2j/xRkv6PbJnbGcDlETGznA0z62juujezipTuoz8kveqAsyLi5fK2yqzjOdCbWUWT1Jvsb+HscrfFrBQc6M3MzHLMk/HMzMxyzIHezMwsxxzozczMcsyB3szMLMcc6M3MzHLMgd6sRCTVSxor6VVJd0jq1Y5j/VnSoen9tZI2aaHubpJ2XoFzvC9pUFvLG9VZrlvTJF0k6azlbaOZLT8HerPSmRcRW0XEZmSPPD2xeKOkFVqZMiL+IyJeb6HKbsByB3ozyycHerPO8SSwfsq2n5R0H/C6pGpJv5b0vKSXJX0HskepSrpC0luS/g4MKRxI0mOSRqT3IyWNkfSSpEclrUN2QXF66k3YRdJgSXelczwv6Qtp31UlPSzpNUnXAmrtS0i6V9LotM8Jjbb9LpU/KmlwKltP0kNpnyclbdwRP0wzazuvdW9WYilz3xd4KBVtA2wWEe+lYDkjIraT1B14WtLDwNbARmTPSl8NeB24rtFxBwN/BHZNxxoYEdMkXU329LXfpHr/C/wuIp6StBYwCvg8cCHwVERcLGl/sse1tuZb6Rw9gecl3RURU4HewAsRcbqkC9KxTwGuAU6MiHck7QD8HthjBX6MZraCHOjNSqenpLHp/ZPAn8i61J+LiPdS+d7AFoXxd6AfsAHZ89BviYh6YGJ68EpjOwJPFI4VEdOaaceXgU2kxQl7X0mrpHMckvZ9QNL0Nnyn70n6ano/PLV1KtAA3JbKbwLuTufYGbij6Nzd23AOM+tADvRmpTMvIrYqLkgBb05xEXBqRIxqVG+/DmxHFbBjRMxvoi1tJmk3souGnSJirqTHgB7NVI903s8a/wzMrHN5jN6svEYBJ0nqBiBpw/SQlSeAw9MY/lBg9yb2fQbYVdK6ad+BqXwW0Keo3sPAqYUPkgqB9wngqFS2LzCglbb2A6anIL8xWY9CQRVQ6JU4imxIYCbwnqSvp3NI0patnMPMOpgDvVl5XUs2/j5G0qvAH8h62u4B3knbbgT+1XjHiPgEOIGsm/wllnSd/xX4amEyHvA9YESa7Pc6S2b//5jsQuE1si78D1tp60NAjaQ3gF+QXWgUzAG2T99hD+DiVH408O3UvteAg9rwMzGzDuSn15mZmeWYM3ozM7Mcc6A3MzPLMQd6sxKR1F3SbZLGSXo2LWbTVL33Jb2SxtRfKCr/taQ309j6PZL6p/J1JM1L9cem++YL+zyUFs95TdLVkqo76LtcLOnLK7Dfci2N216SjpX0Tnod20rdMyWF0vK+kn5Q9DN9VdkSxgOL6ldLelHS/UVlTxbtM1HSvaX7dmYrxmP0VlEk1UREXSed67vAFhFxoqQjgK9GxOFN1HsfGBERnzYq3xv4v4iok/RLgIj4YbpguD8trdv4WH0jYqaye+fuBO6IiFs7+ru1laTZEbFKJ51rIPACMILs9r7RwLYRscz6AJKGk02E3DjVafyzPxA4PSL2KCo7Ix27b0Qc0MQx7wL+EhE3dty3Mms/Z/TWJaiZpVXVaInXVLaKpOtTFvyypK+l8tlF+x0q6c/p/Z9Tdvss8CtJ20v6V8rO/ilpo1SvWtJvUjb3sqRTJe1RnKVJ2kvSPW38WgcBN6T3dwJ7ajluXo+Ih4suSp4B1mzDPjPT2xqglizgIelESSc2ri/puPSzfyT1LJwi6Yz0s3mmkNFq6Yfq/ELS6+lnVFh9b7XU6/BSeu3c6DyrKFsad0z6dzsolfeW9EDa51VJhzd3jjbYB3gkIqal4P4IMLKZur8Dzi78fJpwJHBLUfvXBPYnuzhYhqS+ZHcbOKO3LscL5lhXsczSqmQXokst8Zrq/ifZsrGbA0hq7f5vyILkzhFRn/4o75Iy5S8DPwO+Rnar2jrAVmnbQGA68HtJg9PtbMeTlqKVdBvZMrWN/VfK6oYB4wHS8WYAqwKfNqofwMOSAvhDRFzT1M+HJbfPAawr6UVgJvCjiHiysEHSKGB74G9kFxhExNU0bzOyJXd7AOOAH0bE1pJ+B3wTuLTo2KsCXwU2johQGk4ALgcej4ivKhsuaJzFzyfr0ZiZusqfUbbe/0hgYkTsn47fr7lzSDoa+EET7R8XEYdS9PNOPkplS0kXGRMi4qWmrruUPWVwJNkSvgWXkl0Y9Flmh8zBwKNFF1pmXYYDvXUVTS2tOpiml3j9MnBEYcemumabcEdaThayhV9ukLQBWZDtVnTcqwtZdOF8kv4HOEbS9cBOZMGPprrhV9AXI2KCpCHAI5LejIgnChslnQ/UATenoknAWhExVdK2wL2SNi0EmYjYR1KPVH8Pssy2Jf+IiFnArHQx8tdU/gqwRaO6M8iC9p+UjVUXxqv3YMnPpT7VKybgZ5J2JVsudxjZGv6vAL9NQxP3R8STyp4NsMw5IuLmop/BCklB/DyypYebcyDwdNG//wHAlIgYrWx1wKYcSTPZvlm5ueveyk5LL626JfAizS+t2pLibtjG+xcvO/sTsuC2Gdkf9dbOdT1wDNkf8zsKFwLKJtqNbeL1zbTfBLKLlsKDbfqRrQu/dKMjJqT/TiFbKGf7wjZJxwEHAEdHmlATEQvSg2SIiNHAv4ENGx1zPvAX2rZAzYKi9w1FnxtolAyk7749WU/BASx5UE9rjia7cNs2LYk7GegREW+TPeTnFeCnki5o7hySjm7m531nOsfin3eyZiorth6wLvCSsrkRa5ItVrR6UZ0jKOq2B74AfCXVvxXYQ9JNhY2ph2J74IE2/izMOpUzeusKmlta9RmybvN1i5/ORpahngycBlnXfcrqJ0v6PPAWWdfvrBbOVwgAxxWVPwJ8R9I/Cl33abx3oqSJwI/ILkiANmX09wHHkq1qdyjZxLqlxoSVLXdbFRGz0vu9SavKSRpJ1l38pYiYW7TPYGBaGob4HFnvx7vKHiLTJyImpQuL/ckepoOkU1Kbr2ilzS1K5+gVEQ9Kehp4N216FDgJuLTQdR8RxVl9P7KseJGk3YG10/HWSN/lJkmfAf/R3DnakNGPIus1KAzl7A2cW1whIl5h6Uf+vk/RREhJ/YAvkV3YFfY5t3CcdFF6VkQcs+SoHErWG7HUswTMugpn9NYVNLm0agtLvP4UGJAmb73EknXgzyHr5v0nWfd2c34F/DyNcRdf7F5Ltgzsy+m4RxVtuxkYHxFvLMf3+hOwqqRxwBmpfUhaQ9KDqc5qwFPpfM8BD0REIUu+gmxM+BEtfRvdrqmNY8my3hPTBVBv4D5JLwNjgSlAYZ+NaaI3YQX0Ae5P53gqfS+A7wO7S3qFbLb7Jo32u5lsGd5XyLr430zlmwPPpe9yIdm/bXPnaFH6GfwEeD69Li7qfr9W0og2HOarwMMRMafVmks07gEw61J8e51ZG0i6AngxIv5U7rasiDTWfUhELCx3W8yscznQm7VC0miyMf69ImJBa/XNzLoSB3ozM7Mc8xi9mZlZjjnQm5mZ5ZgDvZmZWY450JuZmeWYA72ZmVmOOdCbmZnl2P8HI6Ymc/ykD8gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}